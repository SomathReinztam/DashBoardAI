# DashBoardAI üß†üìä Agente Multi-Rol para An√°lisis y Visualizaci√≥n de Datos
## Por Thomas Mart√≠nes Vel√°sques - Estudiante de Matem√°ticas - Universidad Nacional 

**Proyecto creado para la Hackat√≥n Deeppunk 2025**

---

### üöÄ ¬øQu√© es DashBoardAI?

DashBoardAI es un sistema multi-agente que automatiza el proceso de an√°lisis y visualizaci√≥n de datos. A partir de un simple archivo CSV, el sistema puede generar de forma aut√≥noma:

1.  Un **informe estad√≠stico detallado** en formato Markdown.
2.  Un Markdown que contiene una **aplicaci√≥n web interactiva (dashboard)** construida con Streamlit.
3.  Se supone que los datos ya estan limpios. El agente solo se l√≠mita al an√°lisis.

Este proyecto utiliza el poder de los Grandes Modelos de Lenguaje (LLMs) y arquitecturas de agentes, como **LangGraph** y **LangChain**, para orquestar un flujo de trabajo cognitivo donde diferentes agentes especializados colaboran para transformar datos crudos en insights accionables y visualizaciones funcionales.

### ‚ú® Caracter√≠sticas Principales

-   ü§ñ **Arquitectura Multi-Agente:** Un agente *Analista* interpreta los datos y un agente *Coder* escribe el c√≥digo del dashboard, simulando un equipo de ciencia de datos.
-   üõ†Ô∏è **Agentes con Herramientas:** Los agentes no solo razonan, sino que ejecutan c√≥digo Python (`PythonAstREPLTool`) para realizar an√°lisis reales sobre el DataFrame.
-   üîÑ **Flujo de Trabajo Aut√≥nomo:** El sistema gestiona el ciclo completo: desde la ingesta de datos y el an√°lisis hasta la generaci√≥n de un producto final archivo Markdown que contiene el ejecutable (el dashboard).
-   üíª **Generaci√≥n de C√≥digo Funcional:** El resultado final no es solo un informe est√°tico, sino un archivo marckdown que contiene aplicaci√≥n Streamlit lista para ser desplegada.

---

### üîß Flujo de Trabajo y Arquitectura

El proceso se modela como un grafo de estados donde cada nodo representa un agente o una herramienta.

![Grafo del Agente](https://github.com/SomathReinztam/DashBoardAI/raw/main/DashBoardAI/grafo_del_agente.png)

1.  **Carga de Datos:** El usuario carga un archivo CSV a traves de un DataFrame de pandas.
2.  **Agente Analista (`Analyst`):**
    -   Recibe el DataFrame.
    -   Utiliza la herramienta `PythonAstREPLTool` para ejecutar c√≥digo de an√°lisis (e.g., `df.describe()`, `df.corr()`, etc.).
    -   Genera un informe detallado en Markdown (`report_generado.md`) con sus hallazgos y sugerencias de visualizaci√≥n.
3.  **Agente Programador (`Coder`):**
    -   Recibe el informe del analista.
    -   Escribe el c√≥digo Python para una aplicaci√≥n Streamlit que visualiza los insights del informe usando librer√≠as como Plotly.
    -   Guarda el c√≥digo en un archivo `dashboard_generado.mk`, que contiene el c√≥digo para generar el dashboard en Streamlit.

---

### üìö Tecnolog√≠as Utilizadas

-   **Orquestaci√≥n de Agentes:** LangGraph y LangChain
-   **Modelo de Lenguaje (LLM):** LLaMA3-70B a trav√©s de la API de Groq para inferencia de alta velocidad. Donde resalto que LLama es un LLM de c√≥digo abierto.
-   **Dashboard Interactivo:** Streamlit
-   **Visualizaci√≥n de Datos:** Plotly
-   **An√°lisis de Datos:** Pandas

---

### ‚ñ∂Ô∏è Instalaci√≥n y Uso

Sigue estos pasos para poner en marcha el proyecto en tu entorno local.

#### Prerrequisitos

-   Python 3.10 o superior (desarrollado y probado con Python 3.11).
-   Git para clonar el repositorio.

#### 1. Clonar el Repositorio

```bash
git clone https://github.com/SomathReinztam/DashBoardAI.git
cd DashBoardAI
```

#### 2. Crear un Entorno Virtual (Recomendado)

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

#### 3. Instalar Dependencias

Todas las librer√≠as necesarias se encuentran en `requirements.txt`.

```bash
pip install -r requirements.txt
```

#### 4. Configurar la API Key

Este proyecto requiere una clave de API de **Groq**. Puedes obtener una de forma gratuita en [su plataforma](https://console.groq.com/keys).

Crea un archivo llamado `.env` en la ra√≠z del proyecto y a√±ade tu clave:

```
# .env
GROQ_API_KEY="tu_api_key_aqui"
```

El programa cargar√° esta variable de entorno autom√°ticamente.

#### 5. Ejecutar el Agente

Aseg√∫rate de tener tu archivo de datos (por ejemplo, `mi_dataset.csv`) en el directorio del proyecto. Luego, ejecuta el script principal:

```bash
# Reemplaza 'ruta/a/tu/dataset.csv' con la ubicaci√≥n de tu archivo
python main.py --file 'ruta/a/tu/dataset.csv'
```

#### 6. Revisar los Resultados

Una vez que el script finalice, encontrar√°s dos archivos nuevos:

-   `report_generado.md`: El informe de an√°lisis estad√≠stico.
-   `dashboard_generado.py`: El script de la aplicaci√≥n Streamlit.

#### 7. Lanzar el Dashboard

Para ver tu dashboard interactivo, ejecuta el siguiente comando en tu terminal:

```bash
streamlit run dashboard_generado.py
```

---

### üìÇ Estructura de Entrada y Salida

-   **Entrada:** Cualquier archivo CSV que pueda ser le√≠do por `pandas.read_csv()`.
-   **Salida:**
    -   `report_generado.md`: Un archivo Markdown con el informe de an√°lisis.
    -   `dashboard_generado.py`: Un script de Python listo para ser ejecutado con Streamlit.

---

### ‚ö†Ô∏è Advertencia de Seguridad Importante

Este proyecto utiliza la herramienta `PythonAstREPLTool`, que otorga al agente la capacidad de **ejecutar c√≥digo Python arbitrario** en el sistema donde se corre. Esto representa una vulnerabilidad de seguridad significativa.


**No ejecutes este agente en un entorno de producci√≥n o con datos sensibles sin implementar medidas de sandboxing adecuadas.** √ösalo con fines educativos y de experimentaci√≥n en un entorno controlado.

### ‚ö†Ô∏è Nota

Si quieres que el agente analice un data frame diferente al proporcionado en este repositorio debes especificar el cambio dentro de la bariable Coder_system_template en el archivo dashBoardAI.py, cambiando el nombre de la referencia del data frame del anterior `df = pd.read_csv(iris.csv, sep=',')` a el nuevo.

---

### ‚öñÔ∏è Consideraciones √âticas

-   **Transparencia:** Los LLMs pueden cometer errores o "alucinar". Revisa siempre el informe y el c√≥digo generado antes de tomar decisiones basadas en ellos.
-   **Privacidad de Datos:** No utilices este sistema con datos personales o sensibles sin haber aplicado previamente t√©cnicas de anonimizaci√≥n.
-   **Uso Responsable:** Esta herramienta est√° dise√±ada para aumentar y complementar el juicio humano, no para reemplazarlo. La supervisi√≥n de un experto es fundamental.

---

### üåç Impacto y Visi√≥n

-   **Democratizaci√≥n del An√°lisis:** Permite a usuarios sin experiencia en programaci√≥n obtener an√°lisis y dashboards interactivos de forma r√°pida.
-   **Aceleraci√≥n del Prototipado:** Reduce dr√°sticamente el tiempo necesario para la exploraci√≥n inicial de nuevos conjuntos de datos.
-   **Sistemas Auto-Explicativos:** El informe generado sirve como documentaci√≥n del "razonamiento" del LLM, abriendo la puerta a sistemas de IA m√°s transparentes.
-  **Divulgaci√≥n de como se desarrollan los agentes** En internet, creo que no hay mucho contenido en espa√±ol del como se desarrollan los agentes a traves del framework de **langGraph** y **langChain**, este trabajo sirve como un muy buen ejemplo para empezar a estudiar el desarrollo de agentes dado que la arquitectura desarrollada aqu√≠ es simple.

---

### ‚ú® Cosas a mejorar

- La arquitectura del sistema multi-agente es bastante sencilla, principalmente debido a las limitaciones de utilizar una API gratuita, lo cual restringe las opciones de dise√±o e implementaci√≥n.

- En futuras versiones del proyecto, se podr√° mejorar la abstracci√≥n y robustez del sistema. Actualmente, cambiar el DataFrame a analizar requiere modificaciones manuales poco pr√°cticas. Adem√°s, se podr√≠a trabajar para que el resultado final sea un ejecutable aut√≥nomo del dashboard en Python, en lugar de un archivo Markdown que lo contiene.

- Tambi√©n debido a las restricciones de la API gratuita, fue necesario limitar la cantidad de DataFrames que pueden analizarse en paralelo. Esta es una limitaci√≥n significativa, ya que en contextos reales los datasets suelen estar relacionados y deben ser analizados de forma conjunta.

- El agente no hace limpiesa de datos o pre-procesamiento de los datos. En futuras versiones esta caracteristica se podr√≠a implementar
